{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Adoption\n",
    "\n",
    "Code from https://github.com/graykode/gpt-2-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Reproducibility\n",
    "seed = random.randint(0, 2147483647)\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "# GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# GPTConfig - HuggingFace style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Config(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size_or_config_json_file=50257,\n",
    "            n_positions=1024,\n",
    "            n_ctx=1024,\n",
    "            n_embd=768,\n",
    "            n_layer=12,\n",
    "            n_head=12,\n",
    "            layer_norm_epsilon=1e-5,\n",
    "            initializer_range=0.02,\n",
    "            pdrop=0.1,\n",
    "    ):\n",
    "        self.vocab_size = vocab_size_or_config_json_file\n",
    "        self.n_ctx = n_ctx\n",
    "        self.n_positions = n_positions\n",
    "        self.n_embd = n_embd\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.layer_norm_epsilon = layer_norm_epsilon\n",
    "        self.initializer_range = initializer_range\n",
    "        self.pdrop = pdrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Wandb managing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtst008\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/tst008/PACT-replica/runs/13pm236v\" target=\"_blank\">wise-bee-1</a></strong> to <a href=\"https://wandb.ai/tst008/PACT-replica\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B online, running your script from this directory will now sync to the cloud.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"PACT-replica\", entity=\"tst008\")\n",
    "!wandb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Norm: $y = \\frac{x-E[x]}{\\sqrt{Var[x] + \\epsilon}} * \\gamma + \\beta$\n",
    "\n",
    "- Where x is a mini-batch of input, with dimension `normalized_shape`.\n",
    "- $\\gamma$ and $\\beta$ are $\\textit{learnable}$ affine transform parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = LayerNorm(embedding_dim)\n",
    "layer_norm(embedding).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: $N, C, L$, Output: $N, C, L_o$\n",
    "\n",
    "$out(N, C_j) =  bias(C_j) + \\sum^{C_i - 1}_{k=1}w(C_j, k) * inp(N_i, k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nf, nx):\n",
    "        super(Conv1D, self).__init__()\n",
    "        self.nf = nf\n",
    "        self.nx = nx\n",
    "        w = torch.empty(nx, nf)\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        self.weight = Parameter(w)\n",
    "        self.bias = Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.nx == x.shape[-1], f\"Shape mismatched, expected shape: {list(x.shape[:-1])+[self.nx]}, got shape: {list(x.shape)}\"\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
    "        x = x.view(*size_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Conv1D(10, 50)\n",
    "i = torch.randn(20, 16, 50)\n",
    "m(i).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies multi-head attention \n",
    "\n",
    "- Query: representation of current word used to score against other words\n",
    "- Key: labels for all potentially relevant words in segment\n",
    "- Value: Actual word representations. Relevancy of each word is added up to represent current word\n",
    "\n",
    "Input size, output size??\n",
    "https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, nx, n_ctx, config, scale=False):\n",
    "        super(Attention, self).__init__()\n",
    "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "        # [switch nx => n_state from Block to Attention to keep identical to TF implem]\n",
    "        assert n_state % config.n_head == 0\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.n_head = config.n_head\n",
    "        self.split_size = n_state\n",
    "        self.scale = scale\n",
    "        self.c_attn = Conv1D(n_state * 3, nx)\n",
    "        self.c_proj = Conv1D(n_state, nx)\n",
    "        self.attn_drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "        self.resid_drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "\n",
    "    def _attn(self, q, k, v):\n",
    "        w = torch.matmul(q, k)\n",
    "        if self.scale:\n",
    "            w = w / math.sqrt(v.size(-1))\n",
    "        nd, ns = w.size(-2), w.size(-1)\n",
    "        try:\n",
    "            b = self.bias[:, :, ns-nd:ns, :ns]\n",
    "            w = w * b - 1e10 * (1 - b)\n",
    "            w = nn.Softmax(dim=-1)(w)\n",
    "        except:\n",
    "            print(b.shape, w.shape)\n",
    "            raise\n",
    "        return w, torch.matmul(w, v)\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_x_shape = x.size()[:-2] + (x.size(-2) * x.size(-1),)\n",
    "        return x.view(*new_x_shape)  # in Tensorflow implem: fct merge_states\n",
    "\n",
    "    def split_heads(self, x, k=False):\n",
    "        new_x_shape = x.size()[:-1] + (self.n_head, x.size(-1) // self.n_head)\n",
    "        x = x.view(*new_x_shape)  # in Tensorflow implem: fct split_states\n",
    "        if k:\n",
    "            return x.permute(0, 2, 3, 1)  # (batch, head, head_features, seq_length)\n",
    "        else:\n",
    "            return x.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        # Begin by looking at the shape of all these\n",
    "#         print(f\"x:{x.shape}\")\n",
    "        x = self.c_attn(x)\n",
    "#         print(f\"(after c_attn) x:{x.shape}\")\n",
    "        query, key, value = x.split(self.split_size, dim=2)\n",
    "#         print(f\"query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key, k=True)\n",
    "        value = self.split_heads(value)\n",
    "#         print(f\"(after split_heads()) query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        if layer_past is not None:\n",
    "            past_key, past_value = layer_past[0].transpose(-2, -1), layer_past[1]  # transpose back cf below\n",
    "            key = torch.cat((past_key, key), dim=-1)\n",
    "            value = torch.cat((past_value, value), dim=-2)\n",
    "#             print(f\"(in if layer_past is not None) query:{query.shape}, key:{key.shape}, value:{value.shape},\")\n",
    "        present = torch.stack((key.transpose(-2, -1), value))  # transpose to have same shapes for stacking\n",
    "#         print(f\"present:{present.shape}\")\n",
    "        w, a = self._attn(query, key, value)\n",
    "#         print(f\"(output of _attn) a:{a.shape}\")\n",
    "        a = self.merge_heads(a)\n",
    "#         print(f\"(output of merge_heads) a:{a.shape}\")\n",
    "        a = self.c_proj(a)\n",
    "#         print(f\"(output of c_proj) a:{a.shape}\")\n",
    "        a = self.resid_drop(a)\n",
    "#         print(f\"(output of resid_drop) a:{a.shape}\")\n",
    "        return a, present, w # Present key and values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test Masked before softmax, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones([1, 1, 1024, 1024]) #torch.Size([1, 12, 1760, 1760])\n",
    "b = torch.ones([1, 12,])\n",
    "nd, ns = w.size(-2), w.size(-1)\n",
    "nd, ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the Gaussian Error Linear Units function:\n",
    "    \n",
    "$y = x * \\Phi(x)$\n",
    "\n",
    "where $\\Phi(x)$ is the Cumulative Distribution Function for Gaussian Distribution\n",
    "\n",
    "... tho I'm not seeing that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6732, 0.5304])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu(torch.randn(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D(n_state, n_embd) $\\implies$ gelu $\\implies$ Conv1D(n_embd, n_state)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_state, config):  # in MLP: n_state=3072 (4 * n_embd)\n",
    "        super(MLP, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.c_fc = Conv1D(n_state, nx)\n",
    "        self.c_proj = Conv1D(nx, n_state)\n",
    "        self.act = gelu\n",
    "        self.dropout = nn.Dropout(config.pdrop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.c_fc(x))\n",
    "        h2 = self.c_proj(h)\n",
    "        h2 = self.dropout(h2)\n",
    "        return h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "config = argparse.Namespace(\n",
    "    n_embd = 15,\n",
    "    pdrop = .1,\n",
    ")\n",
    "i = torch.randn(10, 3, 15)\n",
    "mlp = MLP(30, config)\n",
    "mlp(i).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns: \n",
    "- $x + (LN(x) \\implies ATTN(x)) + MLP(x)$\n",
    "- `present` the cumulative keys and values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_ctx, config, scale=False):\n",
    "        super(Block, self).__init__()\n",
    "        nx = config.n_embd\n",
    "        self.ln_1 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.attn = Attention(nx, n_ctx, config, scale)\n",
    "        self.ln_2 = LayerNorm(nx, eps=config.layer_norm_epsilon)\n",
    "        self.mlp = MLP(4 * nx, config)\n",
    "\n",
    "    def forward(self, x, layer_past=None):\n",
    "        a, present, _ = self.attn(self.ln_1(x), layer_past=layer_past)\n",
    "        x = x + a\n",
    "        m = self.mlp(self.ln_2(x))\n",
    "        x = x + m\n",
    "        return x, present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder-only Transformer GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.n_layer = config.n_layer\n",
    "        self.n_embd = config.n_embd\n",
    "        self.n_vocab = config.vocab_size\n",
    "\n",
    "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.wpe = nn.Embedding(config.n_positions, config.n_embd)\n",
    "        \n",
    "        self.drop = nn.Dropout(config.pdrop, inplace=False)\n",
    "        \n",
    "        block = Block(config.n_ctx, config, scale=True)\n",
    "        self.h = nn.ModuleList([copy.deepcopy(block) for _ in range(config.n_layer)])\n",
    "        self.ln_f = LayerNorm(config.n_embd, \n",
    "                              eps=config.layer_norm_epsilon)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, input_ids, \n",
    "                position_ids=None, \n",
    "                token_type_ids=None, \n",
    "                past=None):\n",
    "        if past is None:\n",
    "            past_length = 0\n",
    "            past = [None] * len(self.h)\n",
    "        else:\n",
    "            past_length = past[0][0].size(-2)\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(past_length, input_ids.size(-1) + past_length, dtype=torch.long,\n",
    "                                        device=input_ids.device)\n",
    "            position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        input_shape = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, input_ids.size(-1))\n",
    "        position_ids = position_ids.view(-1, position_ids.size(-1))\n",
    "\n",
    "        inputs_embeds = self.wte(input_ids)\n",
    "        position_embeds = self.wpe(position_ids)\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1))\n",
    "            token_type_embeds = self.wte(token_type_ids)\n",
    "        else:\n",
    "            token_type_embeds = 0\n",
    "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
    "        presents = []\n",
    "        for block, layer_past in zip(self.h, past):\n",
    "            hidden_states, present = block(hidden_states, layer_past)\n",
    "            presents.append(present)\n",
    "        hidden_states = self.drop(hidden_states)\n",
    "        hidden_states = self.ln_f(hidden_states)\n",
    "        output_shape = input_shape + (hidden_states.size(-1),)\n",
    "        return hidden_states.view(*output_shape), presents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2LMHead(nn.Module):\n",
    "    def __init__(self, model_embeddings_weights, config):\n",
    "        super(GPT2LMHead, self).__init__()\n",
    "        self.n_embd = config.n_embd\n",
    "        self.set_embeddings_weights(model_embeddings_weights)\n",
    "\n",
    "    def set_embeddings_weights(self, model_embeddings_weights):\n",
    "        embed_shape = model_embeddings_weights.shape\n",
    "        self.decoder = nn.Linear(embed_shape[1], embed_shape[0], bias=False)\n",
    "        self.decoder.weight = model_embeddings_weights  # Tied weights\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        # Truncated Language modeling logits (we remove the last token)\n",
    "        # h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)\n",
    "        lm_logits = self.decoder(hidden_state)\n",
    "        return lm_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2LMHeadModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GPT2LMHeadModel, self).__init__()\n",
    "        self.transformer = GPT2Model(config)\n",
    "        self.lm_head = GPT2LMHead(self.transformer.wte.weight, config)\n",
    "\n",
    "    def set_tied(self):\n",
    "        \"\"\" Make sure we are sharing the embeddings\n",
    "        \"\"\"\n",
    "        self.lm_head.set_embeddings_weights(self.transformer.wte.weight)\n",
    "\n",
    "    def forward(self, input_ids, position_ids=None, token_type_ids=None, lm_labels=None, past=None):\n",
    "        hidden_states, presents = self.transformer(input_ids, position_ids, token_type_ids, past)\n",
    "        lm_logits = self.lm_head(hidden_states)\n",
    "        if lm_labels is not None:\n",
    "            shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = lm_labels[..., 1:].contiguous()\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "#             loss_fct = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "#             loss = loss_fct(lm_logits.view(-1, lm_logits.size(-1)), lm_labels.view(-1))\n",
    "            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            return loss, lm_logits, presents\n",
    "        return lm_logits, presents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import regex as re\n",
    "from os.path import expanduser\n",
    "# from functools import lru_cache\n",
    "\n",
    "# @lru_cache()\n",
    "def bytes_to_unicode():\n",
    "    \"\"\"\n",
    "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
    "    The reversible bpe codes work on unicode strings.\n",
    "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
    "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
    "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
    "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
    "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
    "    \"\"\"\n",
    "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
    "    cs = bs[:]\n",
    "    n = 0\n",
    "    for b in range(2**8):\n",
    "        if b not in bs:\n",
    "            bs.append(b)\n",
    "            cs.append(2**8+n)\n",
    "            n += 1\n",
    "    cs = [chr(n) for n in cs]\n",
    "    return dict(zip(bs, cs))\n",
    "\n",
    "def get_pairs(word):\n",
    "    \"\"\"Return set of symbol pairs in a word.\n",
    "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
    "    \"\"\"\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "    return pairs\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, encoder, bpe_merges, errors='replace'):\n",
    "        self.encoder = encoder\n",
    "        self.decoder = {v:k for k,v in self.encoder.items()}\n",
    "        self.errors = errors # how to handle errors in decoding\n",
    "        self.byte_encoder = bytes_to_unicode()\n",
    "        self.byte_decoder = {v:k for k, v in self.byte_encoder.items()}\n",
    "        self.bpe_ranks = dict(zip(bpe_merges, range(len(bpe_merges))))\n",
    "        self.cache = {}\n",
    "        self.special_tokens = []\n",
    "\n",
    "        # Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions\n",
    "        self.re_pattern = r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "        self.pat = re.compile(self.re_pattern)\n",
    "        \n",
    "    def add_special_token(self, s):\n",
    "        if s in self.special_tokens:\n",
    "            print(f\"Token {s} already added\")\n",
    "        self.special_tokens.append(s)\n",
    "        if s in self.encoder: \n",
    "            # Special token already known, but regex pattern cannot capture fully yet\n",
    "            pass\n",
    "        else:\n",
    "            self.encoder[s] = len(self.encoder)+1\n",
    "            self.decoder[len(self.encoder)+1] = s\n",
    "        s = s.replace(\"|\", r\"\\|\")\n",
    "        self.re_pattern = \" \" + s + \"|\" + self.re_pattern\n",
    "        self.pat = re.compile(self.re_pattern)\n",
    "\n",
    "    def bpe(self, token):\n",
    "        # Also don't split on special tokens\n",
    "        if token in self.special_tokens:\n",
    "            return token\n",
    "        if token in self.cache:\n",
    "            return self.cache[token]\n",
    "        word = tuple(token)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        if not pairs:\n",
    "            return token\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_ranks:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
    "                    new_word.append(first+second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "        word = ' '.join(word)\n",
    "        self.cache[token] = word\n",
    "        return word\n",
    "\n",
    "    def encode(self, text):\n",
    "        bpe_tokens = []\n",
    "        for token in re.findall(self.pat, text):\n",
    "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
    "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
    "        return bpe_tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        text = ''.join([self.decoder[token] for token in tokens])\n",
    "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=self.errors)\n",
    "        return text\n",
    "\n",
    "def get_encoder():\n",
    "    home = expanduser(\"~\")\n",
    "    with open(os.path.join(home, 'data/GPT2/encoder.json'), 'r') as f:\n",
    "        encoder = json.load(f)\n",
    "    with open(os.path.join(home, 'data/GPT2/vocab.bpe'), 'r', encoding=\"utf-8\") as f:\n",
    "        bpe_data = f.read()\n",
    "    bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
    "    enc = Encoder(\n",
    "        encoder=encoder,\n",
    "        bpe_merges=bpe_merges,\n",
    "    )\n",
    "    enc.add_special_token(\"<|endoftext|>\")\n",
    "    enc.add_special_token(\"<|GOAL|>\")\n",
    "    enc.add_special_token(\"<|PROOFSTEP|>\")\n",
    "    print(enc.special_tokens)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_size_or_config_json_file=50257,\n",
    "n_positions=1024,\n",
    "n_ctx=1024,\n",
    "n_embd=768,\n",
    "n_layer=12,\n",
    "n_head=12,\n",
    "layer_norm_epsilon=1e-5,\n",
    "initializer_range=0.02,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use an 80-5-15 train-validation-test split. We split all\n",
    "datapoints deterministically by theorem name, by hashing\n",
    "each name to a float in (0, 1)\n",
    "\n",
    "For fine-tuning a model, we load saved parameters but reinitialize the optimizer. We start each training for a fixed\n",
    "number of tokens (defining the cosine schedule) and record\n",
    "the number of tokens consumed as we reach a minimal validation loss. We use the minimum validation loss snapshot\n",
    "to evaluate each model on our held-out test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "# Fine Tuning\n",
    "\n",
    "https://towardsdatascience.com/how-to-fine-tune-gpt-2-for-text-generation-ae2ea53bc272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>goal_pp</th>\n",
       "      <th>decl_name</th>\n",
       "      <th>open_namespaces</th>\n",
       "      <th>filename</th>\n",
       "      <th>line</th>\n",
       "      <th>column</th>\n",
       "      <th>proof_key</th>\n",
       "      <th>human_tactic_code</th>\n",
       "      <th>tactic_class</th>\n",
       "      <th>cleaned_goal</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b; unfold read read'; simp [array.read_e...</td>\n",
       "      <td>semicolon</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b; unfold read read'</td>\n",
       "      <td>semicolon</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>13</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>unfold read read'</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>32</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>simp [array.read_eq_read']</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...</td>\n",
       "      <td>buffer.read_eq_read'</td>\n",
       "      <td>buffer</td>\n",
       "      <td>lean/library/data/buffer.lean</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>lean/library/data/buffer.lean:49:1</td>\n",
       "      <td>cases b</td>\n",
       "      <td>named</td>\n",
       "      <td>α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            goal_pp  \\\n",
       "0           0  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "1           1  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "2           2  α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...   \n",
       "3           3  α : Type u,\\n_inst_1 : inhabited α,\\ni b_fst :...   \n",
       "4           4  α : Type u,\\n_inst_1 : inhabited α,\\nb : buffe...   \n",
       "\n",
       "              decl_name open_namespaces                       filename  line  \\\n",
       "0  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "1  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "2  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "3  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "4  buffer.read_eq_read'          buffer  lean/library/data/buffer.lean    49   \n",
       "\n",
       "   column                           proof_key  \\\n",
       "0      30  lean/library/data/buffer.lean:49:1   \n",
       "1      11  lean/library/data/buffer.lean:49:1   \n",
       "2      13  lean/library/data/buffer.lean:49:1   \n",
       "3      32  lean/library/data/buffer.lean:49:1   \n",
       "4       4  lean/library/data/buffer.lean:49:1   \n",
       "\n",
       "                                   human_tactic_code tactic_class  \\\n",
       "0  cases b; unfold read read'; simp [array.read_e...    semicolon   \n",
       "1                         cases b; unfold read read'    semicolon   \n",
       "2                                  unfold read read'        named   \n",
       "3                         simp [array.read_eq_read']        named   \n",
       "4                                            cases b        named   \n",
       "\n",
       "                                        cleaned_goal split  \n",
       "0  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  \n",
       "1  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  \n",
       "2  α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...  test  \n",
       "3  α : Type u,\\t_inst_1 : inhabited α,\\ti b_fst :...  test  \n",
       "4  α : Type u,\\t_inst_1 : inhabited α,\\tb : buffe...  test  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"~/data/cleaned_training_data/data_and_metadata.csv\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '<|GOAL|>', '<|PROOFSTEP|>']\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoder / tokenizer\n",
    "enc = get_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 22 indices\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "prev_length = len(df)\n",
    "df = df[df.goal_pp.apply(lambda x: not pd.isna(x))]\n",
    "df = df.reset_index()\n",
    "print(f\"Dropped {prev_length - len(df)} indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200276/200276 [01:41<00:00, 1970.60it/s]\n",
      "/opt/anaconda/envs/dynamic37/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for un-tokenizable pretty printed goals\n",
    "goal_lengths = []\n",
    "for i in trange(len(df)):\n",
    "    try:\n",
    "        tokens = enc.encode(df.cleaned_goal[i])\n",
    "        if enc.decode(tokens) != df.cleaned_goal[i]:\n",
    "            print(\"shit\")\n",
    "            break\n",
    "        goal_lengths.append(len(tokens))\n",
    "    except:\n",
    "        print(f\"Error at {i}, where text is {df.cleaned_goal[i]} with type {type(df.cleaned_goal[i])}\")\n",
    "        raise\n",
    "sns.distplot(goal_lengths)\n",
    "plt.title(\"Goal length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200276/200276 [00:17<00:00, 11431.95it/s]\n",
      "/opt/anaconda/envs/dynamic37/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for un-tokenizable human written tactics\n",
    "tactic_lengths = []\n",
    "for i in trange(len(df)):\n",
    "    try:\n",
    "        tokens = enc.encode(df.human_tactic_code[i])\n",
    "        if enc.decode(tokens) != df.human_tactic_code[i]:\n",
    "            print(\"shit\")\n",
    "            break\n",
    "        tactic_lengths.append(len(tokens))\n",
    "    except:\n",
    "        print(f\"Error at {i}, where text is {df.human_tactic_code[i]} with type {type(df.human_tactic_code[i])}\")\n",
    "        raise\n",
    "sns.distplot(tactic_lengths)\n",
    "plt.title(\"Tactic length distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of indices to be kept will be 196379 in a total of 200276\n",
      "Length before: 200276\n",
      "Length after: 196379\n"
     ]
    }
   ],
   "source": [
    "keep_indices = []\n",
    "for i in range(len(goal_lengths)):\n",
    "    if goal_lengths[i] + tactic_lengths[i] + 2 <= 1024:\n",
    "        keep_indices.append(i)\n",
    "print(f\"Number of indices to be kept will be {len(keep_indices)} in a total of {len(goal_lengths)}\")\n",
    "\n",
    "print(f\"Length before: {len(df)}\")\n",
    "df = df.iloc[keep_indices, :]\n",
    "df.reset_index()\n",
    "print(f\"Length after: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Put goal and tactic into one place, extend encoder and split train test valid\n",
    "class ProofStep(Dataset):\n",
    "    \n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "#         self.attn_masks = []\n",
    "#             self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        toks = self.tokenizer.encode(' <|GOAL|>' + self.df.cleaned_goal.iloc[idx] + ' <|PROOFSTEP|>' + self.df.human_tactic_code.iloc[idx]) \n",
    "        return toks#, self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AdamW, \n",
    "                          get_linear_schedule_with_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '<|GOAL|>', '<|PROOFSTEP|>']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# Dataset\n",
    "tokenizer = get_encoder()\n",
    "dataset = ProofStep(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157,103 training samples\n",
      "9,818 validation samples\n",
      "29,458 test samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Split into train, validation and test set: 80 - 5 - 15\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.05 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n",
    "print('{:>5,} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"It was a bright cold day in April.\"\n",
    "quiet=False\n",
    "nsamples=1\n",
    "unconditional=False\n",
    "batch_size=1\n",
    "gradient_acc_steps = 32\n",
    "length=-1\n",
    "temperature=0.7\n",
    "top_k=40\n",
    "\n",
    "epochs=21\n",
    "lr=1e-5\n",
    "warmup_steps=200\n",
    "epsilon = 1e-8\n",
    "\n",
    "output_dir=\"./models\" \n",
    "output_prefix=\"wreckgar\"\n",
    "test_mode=False\n",
    "save_model_on_epoch=True\n",
    "sample_every = 100 #sample output every 100 steps\n",
    "\n",
    "# device=torch.device(\"cpu\")\n",
    "# model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# Create the DataLoaders for our datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "# For validation and test the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of current stats file: 0\n",
      "\n",
      "Checkpoint not found, starting from epoch #0, min_val_loss of inf.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint model for resuming\n",
    "\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import json\n",
    "\n",
    "def load_checkpoint(config, output_dir, output_prefix):\n",
    "    files = []\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Creating output directory {output_dir}\")\n",
    "    else:    \n",
    "        files = [f for f in os.listdir(output_dir) if isfile(join(output_dir, f))]\n",
    "\n",
    "    # Find training stats\n",
    "    stats_filename = \"stats.json\"\n",
    "    if stats_filename in files:\n",
    "        with open(os.path.join(output_dir, stats_filename), 'r') as f:\n",
    "            training_stats = json.load(f)\n",
    "    else:\n",
    "        training_stats = []\n",
    "    print(f\"Length of current stats file: {len(training_stats)}\\n\")\n",
    "\n",
    "    # Find checkpoints\n",
    "    r = re.compile(f\"{output_prefix}-[0-9]*.pt\")\n",
    "    model_files = list(filter(r.match, files))\n",
    "    epochs_list = [int(x[ len(output_prefix)+1 : -3 ]) for x in model_files]\n",
    "    model = GPT2LMHeadModel(config)\n",
    "    if epochs_list:\n",
    "        current_epoch = max(epochs_list)\n",
    "        min_val_loss = min([x[\"Valid. Loss\"] for x in training_stats])\n",
    "        model.load_state_dict(\n",
    "                torch.load(os.path.join(output_dir, f\"{output_prefix}-{current_epoch}.pt\"))\n",
    "        )\n",
    "        print(f\"Checkpoint #{current_epoch} found, with min_val_loss of {min_val_loss:.3f}, resuming.\")\n",
    "    else:\n",
    "        current_epoch = 0\n",
    "        min_val_loss = float(\"inf\")\n",
    "        print(f\"Checkpoint not found, starting from epoch #{current_epoch}, min_val_loss of {min_val_loss:.3f}.\")\n",
    "    return model, current_epoch, min_val_loss, training_stats\n",
    "\n",
    "config = GPT2Config()\n",
    "config.vocab_size += 2 # 2 new tokens\n",
    "model, current_epoch, min_val_loss, training_stats = load_checkpoint(config, output_dir, output_prefix)\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of warmup steps: 200\n",
      "Total steps: 103110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = model.cuda()\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = lr,\n",
    "                  eps = epsilon\n",
    "                )\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = (len(train_dataloader) // gradient_acc_steps + 1) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "print(f\"Number of warmup steps: {warmup_steps}\\nTotal steps: {total_steps}\")\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "# For sampling\n",
    "def display_attn_and_confidence(model, context_text):\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output[2].detach()\n",
    "        return hook\n",
    "    \n",
    "    context = enc.encode(context_text)\n",
    "    context = torch.tensor(context, device=device, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    # Getting attention outputs\n",
    "    handles = [\n",
    "        model.transformer.h[x].attn.register_forward_hook(get_activation(f'attn_{x}'))\n",
    "            for x in range(12)\n",
    "    ]\n",
    "\n",
    "    # Display next token confidence\n",
    "    prev = context\n",
    "    with torch.no_grad():\n",
    "        logits, past = model(prev)\n",
    "        logits = logits[:, -1, :] / 0.7\n",
    "        logits = top_k_logits(logits, k=10)\n",
    "        log_probs = F.softmax(logits, dim=-1)\n",
    "        values, prev = torch.topk(log_probs, k=10, dim=-1)\n",
    "\n",
    "    prev = prev.tolist()\n",
    "    for i in range(len(prev[0])):\n",
    "        text = enc.decode([prev[0][i]])\n",
    "        print(f\"{text} -> {values[0][i].item()}\")\n",
    "    [handle.remove() for handle in handles]\n",
    "\n",
    "    # Visualize attention maps\n",
    "    idx = 0\n",
    "    input_data = np.arange(context.shape[-1])\n",
    "    attn_maps = [[(torch.sum(activation[f'attn_{x}'], dim=1)/12).detach().cpu().numpy() \n",
    "                         for x in range(12)]]\n",
    "    num_heads = 12\n",
    "    num_layers = 1\n",
    "    seq_len = input_data.shape[0]\n",
    "    fig_size = 4 if num_heads == 1 else 3\n",
    "    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n",
    "    if num_layers == 1:\n",
    "        ax = [ax]\n",
    "    if num_heads == 1:\n",
    "        ax = [[a] for a in ax]\n",
    "    for row in range(num_layers):\n",
    "        for column in range(num_heads):        \n",
    "            im = ax[row][column].imshow(attn_maps[row][column][0], origin='upper', vmin=0, vmax=1, cmap='bone')\n",
    "            ax[row][column].set_xticks(list(range(seq_len)))\n",
    "            ax[row][column].set_xticklabels(input_data.tolist())\n",
    "            ax[row][column].set_yticks(list(range(seq_len)))\n",
    "            ax[row][column].set_yticklabels(input_data.tolist())\n",
    "            ax[row][column].set_title(f\"Layer {column+1}\")\n",
    "            context_words = [enc.decode([x]).strip(' ') for x in context.cpu().numpy()[0]]\n",
    "            if column == 0:\n",
    "                ax[row][column].set_yticklabels(context_words)\n",
    "            ax[row][column].set_xticklabels(context_words, rotation=90)\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.91, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 21 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [02:56, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3,200  of  157,103. Loss:   nan.   Elapsed: 0:02:57.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample_sequence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-fbeb4934c217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# Generate a sample sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             out = sample_sequence(\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_sequence' is not defined"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "# Wandb manage model weights statistics \n",
    "wandb.watch(model)\n",
    "\n",
    "total_t0 = time.time()\n",
    "# training_stats = []\n",
    "# min_val_loss = float('inf')\n",
    "\n",
    "for epoch_i in range(current_epoch+1, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    loss = 0\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        \n",
    "        b_input_ids = batch[0].to(device).unsqueeze(0) # Need to have 2 sizes\n",
    "        \n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids,\n",
    "                        lm_labels=b_input_ids,) \n",
    "#                           attention_mask=b_masks,)\\\n",
    "#         print(outputs)\n",
    "#         raise\n",
    "        loss = outputs[0] \n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        loss /= gradient_acc_steps \n",
    "        \n",
    "        # Attention table\n",
    "        \n",
    "        # Get sample every x batches.\n",
    "        if (step/gradient_acc_steps) % sample_every == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Step {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "            model.eval()\n",
    "            \n",
    "            # Generate a sample sequence\n",
    "            out = sample_sequence(\n",
    "                model=model, length=200,\n",
    "                context=random.randint(1,30000),\n",
    "                batch_size=1,\n",
    "                temperature=0.95, \n",
    "                top_k=50, device=device\n",
    "            )\n",
    "            out = out[:, len(context_tokens):].tolist()\n",
    "            text = enc.decode(out[0])\n",
    "            print(f\">{text}\")\n",
    "\n",
    "            # Show attention table\n",
    "            context_text = \"You are my fire. The one\"\n",
    "            display_attn_and_confidence(model, context_text)\n",
    "            \n",
    "            model.train()\n",
    "        \n",
    "        # Update\n",
    "        loss.backward()\n",
    "        \n",
    "        if (step+1) % gradient_acc_steps == 0 or (step + 1 == len(train_dataloader)):            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch_i,\n",
    "                    'batch_loss': batch_loss\n",
    "                }\n",
    "            )\n",
    "            # wandb log attention table\n",
    "#             wandb.join()\n",
    "        \n",
    "    # Report training\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device).unsqueeze(0)\n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)  \n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs  = model(b_input_ids, \n",
    "                             lm_labels=b_input_ids,) \n",
    "#                            token_type_ids=None, \n",
    "#                              attention_mask = b_masks,          \n",
    "            loss = outputs[0]  \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    # Report validation\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    if min_val_loss > avg_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if save_model_on_epoch:\n",
    "        # Save training stats\n",
    "        with open(os.path.join(output_dir, \"stats.json\"), 'w') as f:\n",
    "            json.dump(training_stats, f)\n",
    "        # Save two files: current best model and current epoch model\n",
    "        if avg_val_loss < min_val_loss:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-best.pt\"),\n",
    "            )\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(output_dir, f\"{output_prefix}-{epoch_i}.pt\"),\n",
    "        )\n",
    "        if epoch_i > 1:\n",
    "            # Remove previous checkpoint\n",
    "            os.remove(os.path.join(output_dir, f\"{output_prefix}-{epoch_i-1}.pt\"))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "type(model) == GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to generate lyrics for test set, get loss, evaluate on persplexity, bleu and rougev \n",
    "# Want to see model's confidence knowing context as well -> attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to check if exists directory, if no, try to create\n",
    "# Try save a dummy model and delete it\n",
    "# These checks are done at the start of notebook\n",
    "# Resume: Check if the directory has a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = GPT2Config()\n",
    "# model = GPT2LMHeadModel(config)\n",
    "model, current_epoch, min_val_loss, training_stats = load_checkpoint(model, output_dir, output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nested_tuple(x):\n",
    "    if type(x) == tuple:\n",
    "        print(len(x))\n",
    "        for y in x:\n",
    "            print_nested_tuple(y)\n",
    "    else:\n",
    "        print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#               Test\n",
    "# ========================================\n",
    "\n",
    "length = 20\n",
    "temperature=0.7\n",
    "top_k=40\n",
    "model.cuda()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "total_eval_loss = 0\n",
    "contexts = []\n",
    "true_lyrics = []\n",
    "generated_lyrics = []\n",
    "# Evaluate data for one epoch\n",
    "for i, batch in tqdm(enumerate(test_dataloader)):\n",
    "#     print(batch.shape)\n",
    "    \n",
    "#     if i % 1 == 0:\n",
    "#         print(f\"{i}/{len(test_dataloader)}\")\n",
    "    \n",
    "    b_input_ids = batch.to(device).view(batch_size, -1)\n",
    "#     print(b_input_ids.shape)\n",
    "#         b_labels = batch[0].to(device)\n",
    "#         b_masks = batch[1].to(device)  \n",
    "\n",
    "    context = b_input_ids[:,:-length].view(batch_size, -1)\n",
    "    prev = context\n",
    "    output = context\n",
    "    past = None\n",
    "    with torch.no_grad():   \n",
    "        # Generate text\n",
    "        for i in range(length):\n",
    "            try:\n",
    "                logits, past = model(prev, \n",
    "                                 past=past)\n",
    "            except:\n",
    "                print(b_input_ids.shape)\n",
    "                raise\n",
    "#             print(logits.shape)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            logits = top_k_logits(logits, k=top_k)\n",
    "            log_probs = F.softmax(logits, dim=-1)\n",
    "#             if sample:\n",
    "            prev = torch.multinomial(log_probs, num_samples=1)\n",
    "#             else:\n",
    "#                 _, prev = torch.topk(log_probs, k=1, dim=-1)\n",
    "            output = torch.cat((output, prev), dim=1)\n",
    "          \n",
    "        # Find loss\n",
    "        loss, _, _  = model(b_input_ids, \n",
    "                         lm_labels=b_input_ids,)\n",
    "    \n",
    "    batch_loss = loss.item()\n",
    "    total_eval_loss += batch_loss\n",
    "    \n",
    "    output = output[:, len(context):].tolist()\n",
    "    text = enc.decode(output[0])\n",
    "#     print(f\"{context}\\n->{text}\")\n",
    "    \n",
    "    contexts.append(enc.decode(list(context[0].cpu().numpy())))\n",
    "    true_lyrics.append(enc.decode(list(batch.view(-1).cpu().numpy())[-length:]))\n",
    "    generated_lyrics.append(text)\n",
    "    \n",
    "#     print(f\"Outputs have {len(outputs)} items:\\noutputs[0]={outputs[0]}\\noutputs[1]={outputs[1].shape}\\noutputs[2]={[x.shape for x in outputs[2]]}\")\n",
    "#     if i >= 3:\n",
    "#         break\n",
    "    \n",
    "# Report validation\n",
    "avg_test_loss = total_eval_loss / len(test_dataloader)\n",
    "test_time = format_time(time.time() - t0)    \n",
    "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss)) #2.25\n",
    "print(\"  Test took: {:}\".format(test_time))\n",
    "len(contexts), len(true_lyrics), len(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contexts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-eec9f8ae131c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"|||\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtrue_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"|||\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mgenerated_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'contexts' is not defined"
     ]
    }
   ],
   "source": [
    "contexts[7]+\"|||\"+true_lyrics[7], contexts[7]+\"|||\"+generated_lyrics[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_lyrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-31ec24393eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mto_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_remove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_lyrics' is not defined"
     ]
    }
   ],
   "source": [
    "# #Finish the sentences when there is a point, remove after that\n",
    "final=[]\n",
    "\n",
    "for i in range(len(true_lyrics)):\n",
    "    to_remove = generated_lyrics[i].split('.')[-1]\n",
    "    final.append(generated_lyrics[i].replace(to_remove,''))\n",
    "\n",
    "# test_set['Generated_lyrics'] = final\n",
    "# test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_lyrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a3ef663fa7d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_lyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrue_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_lyrics' is not defined"
     ]
    }
   ],
   "source": [
    "#Using BLEU score to compare the real sentences with the generated ones\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(len(true_lyrics)):\n",
    "    reference = [true_lyrics[i]]\n",
    "    candidate = final[i]\n",
    "    scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "statistics.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rouge score\n",
    "from rouge import Rouge\n",
    "rouge=Rouge()\n",
    "\n",
    "rouge.get_scores(final, true_lyrics, avg=True, ignore_empty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import RandomSampler, SequentialSampler\n",
    "\n",
    "# # Create the DataLoaders for our datasets.\n",
    "# # We'll take training samples in random order. \n",
    "# train_dataloader = DataLoader(\n",
    "#             train_dataset,  # The training samples.\n",
    "#             sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "#             batch_size = batch_size # Trains with this batch size.\n",
    "#         )\n",
    "# # For validation and test the order doesn't matter, so we'll just read them sequentially.\n",
    "# validation_dataloader = DataLoader(\n",
    "#             val_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#         )\n",
    "# test_dataloader = DataLoader(\n",
    "#             test_dataset, # The validation samples.\n",
    "#             sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
    "#             batch_size = batch_size # Evaluate with this batch size.\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each entry of the matrix is a row in attention table (for wandb logging)\n",
    "        # Log wandb\n",
    "#         columns=[\"s_ind\", \"t_ind\", \"s_word\", \"t_word\", \"attn\"]\n",
    "#         attn_table = wandb.Table(columns=columns)\n",
    "#         temp = context_text.split(\" \")\n",
    "#         for s_ind in range(seq_len):\n",
    "#                 attn_table.add_data(s_ind, t_ind, temp[s_ind], temp[t_ind], attn_maps[row][column][0][s_ind][t_ind])\n",
    "#         wandb.log({\"attn_table\": attn_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
